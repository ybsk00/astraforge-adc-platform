커넥터 전체 활성화 + 역할 정의 + 연동 로직 (Seed / Golden Seed / RAG) 구현안 v1

결론부터 정리하면, 지금 하고 있는 작업은 “일반 시드(벌크) 생성”이 아니라 “Golden Seed(골든셋 후보/최종 100) 생성” 작업입니다.
그리고 PubMed RAG 파이프라인(pubmed_fetch/chunk/embed)은 Golden Seed를 ‘직접 생성’하는 용도가 아니라, “근거(Evidence) 검색/설명/추후 QA”를 위한 문헌 인덱싱 용도로 두는 게 가장 안정적입니다.

0) 다음 액션 (바로 해야 하는 순서)

Mock 경로 완전 차단

golden_seed_job.py에서 data_source 기본값을 clinicaltrials로 고정하고, MOCK_TRIALS 및 _fetch_mock_candidates() 호출 경로를 제거(또는 feature flag로 완전 off).

Golden Seed가 10개 미만으로 “수렴”하는 근본 원인 수정

“임상 데이터는 많이 가져왔는데 최종 후보가 10개 미만”인 패턴은 거의 항상 아래 2가지 때문입니다.

(A) Intervention(약물명) 추출 휴리스틱이 너무 약해서 대부분을 “Unknown/일반 chemo”로 잡음

(B) payload/linker/target 추론이 ‘약물명 문자열’에만 의존 → deruxtecan/vedotin 같은 suffix를 payload로 못 바꿈 → gate에서 탈락

즉, ClinicalTrials 수집 문제가 아니라 “구성요소 추출(Extract) 로직이 빈약”해서 떨어지는 구조입니다.

DB를 Raw / Final(Top100)로 분리

워커는 일단 많이 수집(수백~수천) → program_key 기준 dedup → score/gate → Top100만 Final로 표시

UI는 Final 100만 보여주고, Raw는 “내부 디버그” 탭에서만 확인.

component_catalog에 Target 200개 시딩 후 batch_mode로 확장

HPA/UniProt/OpenTargets가 “기본 5개 타겟”만 도는 이유는 seed가 비어있을 때 디폴트 gene_symbols 5개를 넣기 때문입니다.

해결: component_catalog(type='target')에 200개를 넣고 → UniProt/HPA/OpenTargets는 batch_mode로 catalog 기반 확장.

1) 용어 정리: Seed / Golden Seed / Golden Set / RAG
1.1 Seed(시드, 벌크)

커넥터가 수집해오는 운영용 대량 데이터(원료).

예: PubMed 문헌, UniProt 타겟 프로필, OpenTargets 질환-표적 근거, PubChem/ChEMBL 화합물 레코드 등.

특징: 정답 데이터가 아님, 노이즈/중복/불완전 포함.

1.2 Golden Seed(골든 시드 생성 작업)

“골든셋 100개”를 자동으로 만들기 위한 생성 파이프라인(작업/잡).

원천은 ClinicalTrials(임상) + (옵션) PubMed 근거 보강이 가장 현실적.

1.3 Golden Set(골든셋)

모델 검증/평가의 기준이 되는 정제된 ‘정답에 가까운’ 레퍼런스 집합.

운영 시드(벌크)와 달리 중복 제거, 근거 확인, 표준화된 구성요소(표적/항체/링커/페이로드) 확보가 필수.

1.4 PubMed RAG

PubMed 논문을 literature_documents / literature_chunks에 넣고 임베딩까지 하는 파이프라인.

Golden Set을 “직접 만든다”기보다는:

(a) Golden 후보가 왜 포함됐는지 “근거 보기(Evidence)”를 강화하거나

(b) 추후 챗/검색/리포트 생성에서 문헌을 빠르게 찾게 하는 용도

즉, Golden Seed 생성의 1차 데이터 소스는 ClinicalTrials, RAG는 근거/설명 강화로 두는 게 최적.

2) 커넥터 전체 활성화: 역할과 DB 쓰임새

아래는 “현재 코드가 실제로 쓰는 테이블” 기준의 운영 정의입니다(사용자가 공유한 분석 결과 기반).

2.1 API 커넥터

PubMed

저장: literature_documents, literature_chunks

목적: RAG 인덱스 구축(문헌 검색/근거 설명)

UniProt

저장: target_profiles, raw_source_records, ingestion_cursors, ingestion_logs

목적: 타겟의 기능/단백질/외부참조(ChEMBL/DrugBank 등) 보강

OpenTargets

저장: target_profiles, raw_source_records, ingestion_cursors, ingestion_logs

목적: 질환-표적 근거/우선순위 보강

ClinicalTrials

저장: (커넥터 내부) clinical_trials + 공통 ingestion_*

목적: 임상 기반 후보(ADC 프로그램) 확보 (Golden Seed의 1차 소스)

openFDA

저장: (커넥터 내부) openfda_events + 공통 ingestion_*

목적: 안전성/이상반응 시그널(후속 평가용)

2.2 DB 커넥터

HPA

저장: target_profiles, raw_source_records, ingestion_*

목적: 조직/세포 발현 정보 보강

ChEMBL / PubChem

저장: compound_registry, raw_source_records, ingestion_*

목적: payload 후보/독성/물성(후속 단계) 대비

2.3 시스템 커넥터

Seed

저장: component_catalog

목적: “기본 골드 컴포넌트(표적/항체/링커/페이로드)” 시딩

Resolve

저장: component_catalog

목적: 명칭/ID 매핑 정리(동의어/표준명)

Golden Seed

저장: golden_sets, golden_candidates, golden_candidate_evidence

목적: 골든셋 후보 생성 및 최종 100 선정

3) “왜 ClinicalTrials만 긁는데도 10개 미만이 나오나” 원인 (핵심)

현재 golden_seed_job.py 구조를 보면, ClinicalTrials에서 가져온 study 수가 적어서가 아니라 아래 때문에 최종 후보가 급감합니다.

원인 A — Intervention(ADC 약물명) 추출이 너무 약함

현재 로직:

interventions에서 type == "DRUG" 중
"mab" 또는 "conjugate" 또는 "adc"가 들어간 drug만 우선 선택

못 찾으면 “첫 번째 DRUG”로 fallback

문제:

실제 임상시험 intervention 표기는 케이스가 다양하고, ADC 약물명이 저 조건에 안 걸리는 경우가 많습니다.

fallback이 일반 chemo/병용요법 약물로 잡히면 뒤 단계에서 target/linker/payload 추론이 실패합니다.

원인 B — payload/linker/target 추론이 “suffix 기반”으로 완성되지 않음

현재 payload는 PAYLOAD_DICTIONARY에서 문자열 매칭으로만 뽑습니다.

하지만 ClinicalTrials에서 내려오는 intervention name에는 DXd/MMAE 같은 payload 키워드가 직접 들어있지 않은 경우가 대부분입니다.

대신 ADC는 관행적으로 suffix에 payload/링커가 반영됩니다(예: vedotin, deruxtecan, govitecan, soravtansine, ozogamicin, emtansine 등).

결과:

cand["payload"]가 None/Unknown → hard gate에서 탈락 → 최종이 10개 미만으로 “수렴”.

4) 최적 권장안: “Raw 많이 수집 → Extract 강화 → Dedup → Top100 Final” (DB/워커/UI)
4.1 DB 스키마 변경 (권장)

golden_candidates에 아래 컬럼을 추가하거나, Raw/Final을 분리 테이블로 운영합니다.

옵션 1) 단일 테이블 + 플래그

is_final boolean default false

program_key text

source_nct_id text (source_ref와 분리 권장)

evidence_count int

run_id uuid (connector_runs.id 참조하면 추적이 쉬움)

옵션 2) Raw/Final 테이블 분리(더 권장)

golden_candidate_raw : 많이 적재(수백~수천)

golden_candidates : 최종 100만

또한 Evidence 중복 방지를 위해 unique constraint 권장:

golden_candidate_evidence (candidate_id, ref_id) unique

4.2 Golden Seed 워커 로직 (실데이터 기반, RAG는 옵션)

ClinicalTrials에서 “많이” 가져오기

query.term / query.intr / filter.* 사용 가능하며 파라미터는 Data API 규격을 따릅니다.

각 query 조합별로 pageSize, max_pages_per_query를 올려 최소 500~2000 studies 확보

ADC intervention name 추출 강화(필수)

interventions를 모두 스캔하면서 아래 정규식/키워드에 걸리는 DRUG를 우선 선택:

suffix: vedotin|deruxtecan|govitecan|soravtansine|ozogamicin|emtansine|tesirine|mafodotin|duocarmazine|exatecan 등

포함어: antibody-drug conjugate|ADC|conjugate

없으면 fallback.

payload/linker/target “suffix 기반 추론”을 1차로 둠(필수)

예:

*vedotin → payload=MMAE, linker=Val-Cit(VC) 계열

*deruxtecan → payload=DXd, linker=GGFG 계열

*govitecan → payload=SN-38

*soravtansine → payload=DM4

*emtansine → payload=DM1

*ozogamicin → payload=Calicheamicin

그리고 2차로 PAYLOAD_DICTIONARY / LINKER_DICTIONARY 매칭.

target/antibody 추론

임상시험 conditions, title, briefSummary(가능하면 fields에 포함)에서

HER2, HER3, TROP2, EGFR, CD19, CD22 등 표적 키워드 파싱

또는 component_catalog에 있는 항체/표적 목록을 기반으로 “사전 매칭”.

program_key 기준 dedup

지금처럼 drug_name+target+antibody+linker+payload를 키로 만들되,

단, Unknown이 많으면 program_key가 쏠리므로

Unknown인 후보는 Final 후보군에서 제외하거나

Unknown 비율이 높으면 score를 크게 감점.

score/gate

hard gate:

target/antibody/linker/payload 4요소 완비

evidence_refs >= 1(또는 2)

soft score:

phase(3/2/1)

status(Completed/Active/Recruiting)

evidence(PMID 존재 가점)

표적 다양성(Top100이 특정 표적에 쏠리면 penalty)

Final Top100만 is_final=true

Raw는 남기되 UI는 Final 100만 카운트.

4.3 PubMed RAG는 Golden Seed에 “직접 생성”이 아니라 “근거 보강”으로 붙이기

Golden 후보에 PMID가 있을 경우:

해당 PMID를 PubMed connector로 문헌 테이블에 저장

Evidence 모달에서 PMID 기반으로 title/abstract/snippet을 보여줌

즉,

Golden Seed 생성: ClinicalTrials 중심

근거 설명/검색: PubMed RAG

5) “커넥트로 수집된 시드(벌크)는 어떻게 활용되나?”

정리하면 이렇게 역할이 분리됩니다.

component_catalog(기초 시드)

“표적/항체/링커/페이로드”의 표준명/동의어/외부ID를 담는 기준 사전

Golden Seed의 추출/표준화 단계에서 매핑 테이블로 사용

target_profiles / compound_registry(보강 시드)

UniProt/HPA/OpenTargets/ChEMBL/PubChem이 쌓는 “확장 데이터”

Golden 후보 평가(예: 표적 발현, 질환 근거, payload 물성 등)나 보고서 근거로 활용

literature_documents / literature_chunks(RAG 시드)

PubMed 문헌 인덱스

“왜 이 후보가 골든에 들어갔나?”를 설명하는 Evidence 모달/리포트에서 활용

6) “커넥터 전부 활성화” SQL (예시)

실제 컬럼명이 is_active인지 enabled인지 프로젝트에 맞춰 조정하세요.

-- 1) 모든 커넥터 활성화
update connectors
set is_active = true, updated_at = now();

-- 2) 특정 커넥터만 활성화(권장: 단계적)
update connectors
set is_active = true, updated_at = now()
where lower(name) in (
  'seed', 'resolve',
  'pubmed', 'uniprot', 'opentargets',
  'clinicaltrials', 'openfda',
  'hpa', 'chembl', 'pubchem',
  'golden_seed'
);

7) component_catalog 타겟 200개 시딩 전략 (핵심만)
7.1 초기 200개를 “손으로 다 쓰는” 방식은 비효율

권장: 2단계 혼합 방식

**핵심 30~50개(ADC/항체약물 표적 빈도 상위)**를 curated list로 seed_job에 포함

나머지 150개는 OpenTargets/UniProt에서 확장:

OpenTargets: 암/종양(oncology) 관련 association 상위 타겟

UniProt: membrane protein, cell-surface, receptor 키워드 기반 후보

이때도 component_catalog에 넣을 때 quality_grade='silver'로 구분

7.2 UniProt/HPA/OpenTargets를 “batch_mode”로 돌리기

seed가 비었을 때 “기본 5개 gene_symbols”만 도는 현상은 정상입니다(디폴트 폴백).

해결은 catalog 기반 seed로 batch_mode를 켜는 것입니다.

uniprot_job.py에 이미 batch_mode가 구현되어 있어, catalog의 uniprot_accession을 읽어 확장합니다(현재 코드에도 존재).

8) Golden Seed 커넥터가 어디서 가져오는가? 그리고 RAG를 쓰는가?
8.1 어디서 가져오는가

ClinicalTrials.gov Data API v2 /api/v2/studies

파라미터는 query.term, query.intr, filter.overallStatus, pageSize, pageToken, fields, filter.advanced 등을 사용합니다.

8.2 RAG를 쓰는가?

권장 설계 기준: Golden Seed “생성”에는 RAG를 쓰지 않습니다.

이유: RAG는 문헌 기반 “텍스트 검색/설명”에는 강하지만,

“표적/항체/링커/페이로드를 구조적으로 확정”하는 작업에서 정확도/재현성이 떨어집니다.

대신 RAG는:

후보가 골든에 들어온 “근거”를 보여주거나

검토자가 “왜 이 조합인가?”를 확인하는 용도로 붙입니다.

9) 마지막으로: 지금 보이는 “중복이 너무 많다”에 대한 처리

네, 최종 화면은 100개로 줄어야 정상입니다.
다만 반드시 Raw vs Final을 분리하세요.

Raw: “수집된 모든 후보(중복/노이즈 포함)”

Final: program_key dedup + gate/score + diversity를 적용한 Top100

UI는 Final만 기본 노출:

“Golden Set 후보(최종)” 탭: 100개

“Raw(디버그)” 탭: 전체(권한/옵션으로 숨김)

10) 검증 체크리스트 (성공 판정 기준)

ClinicalTrials fetched가 최소 수백 이상(예: 500~2000)

Extract 단계에서 Unknown 비율이 급감(특히 payload/linker)

Dedup 후에도 program_key unique가 100 이상 확보

Final 100이 만들어지고, 표적이 HER2/HER3/TROP2/EGFR/CD19 등으로 다양성 확보

evidence 테이블이 candidate별로 NCT + (가능하면 PMID)를 포함

Admin UI에서 Final 100만 기본 표시