# Golden Set 검증 및 Storage 최적화 구현 계획 (최종 테스트용)

본 문서는 **실험 데이터 기반 산식 정합성 검증(Golden Set)**과 **대용량 PDF 리포트의 효율적 저장/재사용(Storage 최적화)**을 위한 구현 설계 및 최종 테스트 체크리스트를 정의합니다.  
목표는 (1) 산식 변경 시 성능 회귀를 자동 감지하고, (2) 리포트 중복 생성을 방지하며, (3) 관리자 대시보드에서 검증 결과를 신뢰성 있게 확인할 수 있도록 하는 것입니다.

---

## 1. 범위 및 전제

### 1.1 범위
- 4축 점수: **Bio / Safety / Eng / Clin**
- Golden Set: 승인 ADC 약물 및 대표 후보(초기 3종 + 확장 권장)
- 리포트 산출물: PDF (이미지/표 포함 가능)
- 저장소: Supabase Storage `reports` 버킷
- 메타데이터: Supabase Postgres 테이블로 캐시/검증 결과 저장

### 1.2 전제
- 산식/룰/검색 인덱스/템플릿은 버전으로 관리 가능해야 함
- 동일 입력(동일 버전 키)에서는 **동일 결과**가 재현 가능해야 함
- Golden Set 데이터는 “단위/assay 조건” 메타가 포함되어야 함

---

## 2. Golden Set 기반 산식 회귀 테스트

### 2.1 목표
- 시스템 산출 4축 점수와 Golden Set(실험/문헌 기반 정답 혹은 기준값)을 비교하여 **정합성**을 평가
- 산식 변경 시 기존 성능이 유지되는지 자동 판단하는 **회귀 테스트 체계** 구축

### 2.2 핵심 설계 원칙
1. **정규화(단위/조건) → 비교** 순서 고정
2. “수치 오차”뿐 아니라 **랭킹 안정성(Top-K, 순위 상관)**까지 포함
3. 결과는 “경고 로그”가 아니라 **DB에 적재**하여 추세/감사 가능하게 관리

---

## 3. 데이터 모델 (DB 스키마)

> 최소 구현은 `golden_candidates` 단일 테이블로 가능하나, 실전 운영(단위/assay/다중 측정치)까지 고려하면 아래 분리 구조를 권장합니다.

### 3.1 Golden 후보 메타
- 테이블: `golden_candidates`
- 목적: 후보 약물의 식별자/구성요소/출처 관리

```sql
-- schema_v2_supplement.sql (ADD)
create table if not exists golden_candidates (
  id uuid primary key default gen_random_uuid(),
  drug_name text not null,                -- Kadcyla, Adcetris, Enhertu 등
  target text,                            -- HER2, CD30 등
  antibody text,
  linker text,
  payload text,
  dar_nominal numeric,
  approval_status text,                   -- approved / late_stage / reference
  source_ref text,                        -- DOI/PMID/URL 등
  notes text,
  created_at timestamptz default now()
);
3.2 Golden 실험치(권장)
테이블: golden_measurements

목적: metric별 값/단위/assay/조건/품질 플래그 저장

sql
코드 복사
create table if not exists golden_measurements (
  id uuid primary key default gen_random_uuid(),
  candidate_id uuid not null references golden_candidates(id) on delete cascade,
  metric_name text not null,              -- IC50, Aggregation_pct, SerumStability_hr ...
  value numeric not null,
  unit text,                              -- nM, pM, %, hr 등
  assay_type text,                        -- cell_line, SPR, SEC, DLS ...
  condition text,                         -- buffer, temp, concentration 등 요약
  quality_flag text default 'ok',          -- ok / estimated / low_confidence
  source_ref text,
  created_at timestamptz default now()
);

create index if not exists idx_golden_measurements_candidate on golden_measurements(candidate_id);
create index if not exists idx_golden_measurements_metric on golden_measurements(metric_name);
3.3 Golden 검증 실행/결과 저장(권장)
목적: 매번 검증 시점의 결과를 저장하여 회귀 추세 확인 및 실패 원인 추적

sql
코드 복사
create table if not exists golden_validation_runs (
  id uuid primary key default gen_random_uuid(),
  dataset_version text not null,           -- golden set snapshot version
  scoring_version text not null,           -- scoring formula version
  rule_set_version text,
  retrieval_corpus_version text,
  report_template_version text,
  model_version text,
  status text not null default 'completed', -- completed/failed
  pass boolean not null default false,
  summary jsonb not null default '{}'::jsonb, -- aggregate metrics
  created_at timestamptz default now()
);

create table if not exists golden_validation_metrics (
  id uuid primary key default gen_random_uuid(),
  run_id uuid not null references golden_validation_runs(id) on delete cascade,
  axis text,                               -- Bio/Safety/Eng/Clin or "overall"
  metric text not null,                    -- MAE/RMSE/Spearman/TopKOverlap/KendallTau...
  value numeric,
  threshold numeric,
  pass boolean,
  details jsonb not null default '{}'::jsonb,
  created_at timestamptz default now()
);

create index if not exists idx_golden_val_metrics_run on golden_validation_metrics(run_id);
4. 구현 모듈: golden_set_validator.py (NEW)
4.1 책임
Golden Set(실험치/정답)과 시스템 산출 결과를 비교

정규화(단위/assay/다중 측정치 집계) 수행

지표 산출: MAE/RMSE + Spearman(순위) + Top-K overlap + Kendall Tau(선택)

허용 기준(Threshold) 위반 시 Fail 처리

검증 결과를 DB(golden_validation_runs, golden_validation_metrics)에 저장

4.2 입력/출력 (권장)
입력:

scoring_version

dataset_version

rule_set_version, retrieval_corpus_version, report_template_version, model_version

임계치(설정 파일 또는 DB)

출력:

pass/fail

축별 지표(수치)

Top-K 안정성 지표

실패 원인(어떤 axis/metric이 임계치 위반인지)

4.3 핵심 로직(의사코드)
python
코드 복사
def validate_golden_set(config):
    # 1) golden 후보 및 측정치 로딩
    candidates = load_golden_candidates()
    measurements = load_golden_measurements(candidates)

    # 2) 측정치 정규화 (단위 변환, assay 우선순위, 다중 측정치 집계)
    normalized = normalize_measurements(measurements, rules=config.normalization_rules)

    # 3) 시스템 산출 점수/중간 산출물 로딩 (동일 scoring_version 기준)
    system_scores = compute_or_fetch_scores(candidates, scoring_version=config.scoring_version)

    # 4) 비교 지표 계산
    metrics = {}
    for axis in ["Bio", "Safety", "Eng", "Clin"]:
        y_true = get_expected_axis(axis, normalized, candidates)
        y_pred = system_scores[axis]

        metrics[axis] = {
            "mae": mae(y_true, y_pred),
            "rmse": rmse(y_true, y_pred),
            "spearman": spearman(y_true, y_pred),
        }

    # 5) 랭킹 안정성(Top-K, Kendall tau 등)
    metrics["overall"] = {
        "top10_overlap": topk_overlap(y_true_total, y_pred_total, k=10),
        "kendall_tau": kendall_tau(rank_true, rank_pred),
    }

    # 6) 임계치 비교 -> pass/fail
    passed = evaluate_thresholds(metrics, config.thresholds)

    # 7) DB 적재
    run_id = insert_validation_run(config, passed, summary=aggregate(metrics))
    insert_validation_metrics(run_id, metrics, config.thresholds)

    return passed, metrics
5. Storage 최적화 및 리포트 캐싱
5.1 목표
PDF 리포트를 Supabase Storage에 업로드하여 중앙 관리

동일 입력에 대해 중복 생성 방지(캐싱)

Signed URL 기반 다운로드 제공 + Cache-Control로 성능 개선

5.2 캐시 키 설계 (중요)
run_id + scoring_version만으로는 템플릿/룰/인덱스 변경에 취약합니다. 아래를 포함한 키를 권장합니다.

run_id

scoring_version

rule_set_version

retrieval_corpus_version

report_template_version

(가능하면) model_version

권장:

cache_key = sha256(f"{run_id}:{scoring_version}:{rule_set_version}:{retrieval_corpus_version}:{report_template_version}:{model_version}")

5.3 리포트 캐시 메타 테이블(권장)
sql
코드 복사
create table if not exists report_cache (
  id uuid primary key default gen_random_uuid(),
  run_id uuid not null,
  cache_key text not null,
  bucket text not null default 'reports',
  object_path text not null,              -- e.g. reports/<run_id>/<cache_key>.pdf
  sha256 text,
  bytes bigint,
  scoring_version text not null,
  rule_set_version text,
  retrieval_corpus_version text,
  report_template_version text,
  model_version text,
  created_at timestamptz default now(),
  unique (cache_key)
);
5.4 report_service.py (MODIFY) 책임
(1) cache_key 산출

(2) report_cache 조회 → 있으면 재사용

(3) 없으면 생성 → 업로드 → 메타 저장

(4) Signed URL 발급 (Cache-Control 포함)

동시성(레이스) 방지
report_cache.cache_key에 유니크 인덱스가 있으므로,

생성 전 “선점 레코드(insert)”를 시도하고,

충돌 시 기존 레코드를 조회하여 재사용하는 패턴을 권장

5.5 Storage 메타/캐싱
업로드 시 객체 메타에 Cache-Control 설정 권장

예: public, max-age=604800 (7일) 또는 운영 정책에 맞춰 조정

Signed URL TTL은 너무 짧으면 캐시 효율이 떨어질 수 있음

다운로드 패턴(재시도, 공유)을 고려해 적절히 설정

6. 최종 테스트 계획 (Go / No-Go 기준 포함)
6.1 자동화 테스트 (pytest)
Golden Validator 단위 테스트
 단위 변환 테스트 (nM↔pM, %, hr 등)

 assay 우선순위/quality_flag 가중치 테스트

 다중 측정치 집계 규칙 테스트 (median/trimmed mean)

 축별 MAE/RMSE 산출 테스트

 Spearman/Top-K overlap 산출 테스트

 임계치 위반 시 fail 판정 테스트

 DB 적재(검증 run/metrics insert) 테스트

Storage / Cache 테스트 (Mock Storage)
 cache miss → 생성+업로드 1회 수행

 cache hit → 생성 없이 기존 object_path 재사용

 동시 요청(멀티 스레드/프로세스)에서도 object 1개만 생성

 Signed URL 발급 및 만료 처리 테스트

6.2 수동 검증 (관리자 대시보드)
 동일 Run에서 리포트 2회 생성 요청:

1회차: 생성 시간 기록

2회차: 캐시 재사용으로 시간 단축 확인

 scoring_version 변경 후 동일 Run:

새로운 cache_key로 신규 생성되는지 확인

 Golden 검증 결과 화면:

pass/fail, 축별 지표, 실패 사유(임계치 위반 지표) 표시 확인

6.3 Go / No-Go 기준(초기 권장값 예시)
실제 값은 데이터 규모 및 노이즈에 맞춰 조정하십시오.

축별 MAE

Bio/Safety/Eng/Clin: MAE ≤ 0.10 (예시)

랭킹 안정성

Top10 overlap ≥ 0.70

Spearman ≥ 0.70

동시성

동일 cache_key에 대해 Storage object 생성 1회만 발생

감사성

golden_validation_runs 및 report_cache에 메타가 누락 없이 적재됨

7. 운영/관측(Observability) 권장
7.1 로그
Validator:

dataset_version, scoring_version, pass/fail

축별 지표 및 임계치 위반 항목

Report:

cache_key, cache_hit 여부, 생성 시간, 업로드 시간, bytes, sha256

7.2 관리자 UI 권장 표시
Golden Validation

최근 N회 실행 목록(버전/시간/pass)

축별 지표 트렌드(라인차트)

실패 시 “원인 Top 3 지표” 강조 표시

Report Cache

Run별 리포트 목록(버전별)

cache_hit rate

평균 생성 시간 vs 재사용 시간

8. 파일 변경 요약
신규 파일
services/validator/golden_set_validator.py

Golden Set 로딩/정규화/비교/DB 저장/결과 반환

수정 파일
schema_v2_supplement.sql

golden_candidates (+ 권장 golden_measurements, golden_validation_*, report_cache)

services/report/report_service.py

Storage 업로드 + 캐싱 + Signed URL + 동시성 방지 로직

9. 최종 점검 체크리스트 (실행 전 10분 점검용)
 Golden Set 후보 수: 10개 이상(최소), 가능하면 20개 이상

 핵심 metric(최소 IC50/DAR/Aggregation%) 단위/assay/source_ref 포함

 scoring_version + rule_set_version + retrieval_corpus_version + template_version 고정

 캐시 키에 위 버전들 반영

 report_cache(cache_key) 유니크 인덱스 적용

 동시 생성 방지 검증 완료

 Golden 검증 결과 DB 저장 및 대시보드 표시 확인

 Go/No-Go 기준 수립 및 문서화

10. 결론
현재 계획은 최종 테스트로 진행 가능한 수준입니다.
다만 (1) 단위/assay 정규화, (2) 랭킹 안정성 지표(Top-K, 순위 상관), (3) 캐시 키 확장 및 동시성 방지를 포함하면 “검증 가능한 제품” 수준으로 안정성이 크게 향상됩니다.